device: cuda:0
total_steps: 1e7
random_steps: 20000
update_freq: 4
checkpoint: None # replace with absolute path to checkpoint

Plotter:
  _target_: algo.learner.Plotter
  enable: true
  period: 10

Environment:
  _target_: env.make_env
    #env_name: RiverraidNoFrameskip-v4
  # name: atari_pong
  env_name: PongNoFrameskip-v4

Learner:
  _target_: algo.learner.DreamLearner
  dataset: ${Dataset}
  policy: ${Agent}
  critic: ${Critic}
  world: ${World}
  world_lr: 2e-4
  actor_lr: 4e-5
  critic_lr: 1e-4
  lr: 0.0001
  kl_alpha: 0.8
  kl_beta: 0.1
  rho: 1
  gamma: 0.995
  gae_lambda: 0.95
  imagine_horizon: 15
  entropy_coef: 1e-3
  save_period: 1000
  device: ${device}

Critic:
  _target_: algo.agent.Critic
  latent_size: ${Agent.latent_size}
  hidden_size: 400
  depth: 4

Agent:
  _target_: algo.agent.AtariAgent
  latent_size: 1624
  hidden_size: 400
  depth: 4

World:
  _target_: algo.world.WorldModel
  state_dim: 1024
  hidden_dim: 600
  feat_dim: 600
  embed_dim: 1536
  conv_hid: 48
  mlp_depth: 4
  n_classes: 32
  n_states: 32

Dataset:
  _target_: algo.storage.DreamerDataset
  maxsize: 1000000
  batch_size: 50
  batch_len: 40
  minimal_size: 4

Logger:
  _target_: logger.Logger
  log_period: 500
